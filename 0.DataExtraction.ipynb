{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51055d71",
   "metadata": {},
   "source": [
    "# Data Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable cache \n",
    "fastf1.Cache.enable_cache(\"/Users/ainefernandez/documents/itam/8SEMESTRE/F1 Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the gps by year of interest \n",
    "gps_by_year = {\n",
    "    2019: [\"Bahrain\", \"China\", \"Australia\", \"Japan\", \"Monaco\", \"Spain\", \"Canada\", \n",
    "           \"Austria\", \"Great Britain\", \"Hungary\", \"Belgium\", \"Azerbaijan\", \n",
    "           \"Singapore\", \"Austin\", \"Mexico\", \"Brazil\", \"Abu Dhabi\", \"Monza\",\n",
    "           \"France\", \"Germany\",\"Russia\"],\n",
    "\n",
    "    2020: [\"Bahrain\", \"Spain\", \"Austria\", \"Great Britain\", \"Hungary\", \"Belgium\", \n",
    "           \"Abu Dhabi\", \"Monza\", \"Turkey\", \"Portugal\", \"Russia\", \"Imola\", \n",
    "           \"Eifel\", \"Mugello\", \"Sakhir\",\"70th\",\"Sakhir\"],\n",
    "\n",
    "    2021: [\"Bahrain\", \"Monaco\", \"Spain\", \"Imola\", \"Austria\", \n",
    "           \"Great Britain\", \"Hungary\", \"Belgium\", \"Azerbaijan\", \"Austin\", \n",
    "           \"Mexico\", \"Brazil\", \"Abu Dhabi\", \"Monza\", \"Qatar\", \"Saudi Arabia\",\n",
    "           \"France\", \"Netherlands\", \"Turkey\", \"Russia\",\"Portugal\",\"Styria\"],\n",
    "\n",
    "    2022: [\"Bahrain\", \"Australia\", \"Japan\", \"Monaco\", \"Spain\", \n",
    "           \"Canada\", \"Austria\", \"Great Britain\", \"Hungary\", \n",
    "           \"Belgium\", \"Azerbaijan\", \"Singapore\", \"Austin\", \"Mexico\", \n",
    "           \"Brazil\", \"Abu Dhabi\", \"Monza\", \"Qatar\", \"Miami\", \"Saudi Arabia\",\n",
    "           \"France\", \"Netherlands\"],\n",
    "\n",
    "    2023: [\"Bahrain\", \"Saudi Arabia\", \"Australia\", \"Japan\", \n",
    "           \"Miami\", \"Monaco\", \"Spain\", \"Canada\", \"Austria\", \n",
    "           \"Great Britain\", \"Hungary\", \"Belgium\", \"Netherlands\", \n",
    "           \"Azerbaijan\", \"Singapore\", \"Austin\", \"Mexico\", \"Brazil\", \n",
    "           \"Qatar\", \"Abu Dhabi\", \"Monza\", \"Las Vegas\"],\n",
    "\n",
    "    2024: [\"Bahrain\", \"Saudi Arabia\", \"Australia\", \"Japan\", \n",
    "           \"China\", \"Miami\", \"Monaco\", \"Spain\", \"Canada\", \"Austria\", \n",
    "           \"Great Britain\", \"Hungary\", \"Belgium\", \"Netherlands\", \"Monza\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa384adb",
   "metadata": {},
   "source": [
    "## Qualifying data\n",
    "\n",
    "Obtain Q1 and Q2 data, this is the focus of the project\n",
    "\n",
    "Running and treatment variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f45ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 and Q2 data  \n",
    "q1_combined = pd.DataFrame(columns=[\"Driver\", \"Team\", \"LapTime\", \"Position\", \"GapToKnockout\", \"Session\", \"Year\", \"GP\"])\n",
    "q2_combined = pd.DataFrame(columns=[\"Driver\", \"Team\", \"LapTime\", \"Position\", \"GapToKnockout\",\"Session\", \"Year\", \"GP\"])\n",
    "\n",
    "\n",
    "for year, gps in gps_by_year.items():\n",
    "    \n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the session data\n",
    "            session = fastf1.get_session(year, gp, 'Q')\n",
    "            session.load()\n",
    "\n",
    "            # Extract relevant results\n",
    "            results = session.results[[\"Abbreviation\", \"TeamName\", \"Q1\", \"Q2\"]]\n",
    "            results[\"Q1\"] = results[\"Q1\"].dt.total_seconds()\n",
    "            results[\"Q2\"] = results[\"Q2\"].dt.total_seconds()\n",
    "\n",
    "            # Process Q1 data\n",
    "            q1 = results[[\"Abbreviation\", \"TeamName\", \"Q1\"]].sort_values(by=\"Q1\").reset_index(drop=True)\n",
    "            q1.columns = [\"Driver\", \"Team\", \"LapTime\"]\n",
    "            q1[\"Position\"] = q1.index + 1\n",
    "            knockout_time_q1 = q1.iloc[14][\"LapTime\"]  # 15th place time\n",
    "            q1[\"GapToKnockout\"] = q1[\"LapTime\"] - knockout_time_q1\n",
    "            q1[\"Year\"] = year\n",
    "            q1[\"GP\"] = gp\n",
    "            q1[\"Session\"] = \"Q1\"\n",
    "            q1_combined = pd.concat([q1_combined, q1], ignore_index=True)\n",
    "\n",
    "            # Process Q2 data\n",
    "            q2 = results[[\"Abbreviation\", \"TeamName\", \"Q2\"]].dropna().sort_values(by=\"Q2\").reset_index(drop=True)\n",
    "            q2.columns = [\"Driver\", \"Team\", \"LapTime\"]\n",
    "            q2[\"PositionQ2\"] = q2.index + 1\n",
    "            knockout_time_q2 = q2.iloc[9][\"LapTime\"]  # 10th place time\n",
    "            q2[\"GapToKnockoutQ2\"] = q2[\"LapTimeQ2\"] - knockout_time_q2\n",
    "            q2[\"Year\"] = year\n",
    "            q2[\"GP\"] = gp\n",
    "            q2[\"Session\"] = \"Q2\"\n",
    "            q2_combined = pd.concat([q2_combined, q2], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {gp} {year}: {e}\")\n",
    "\n",
    "\n",
    "q1_combined.to_csv(\"PaperQ1Data.csv\", index=False)\n",
    "q2_combined.to_csv(\"PaperQ2Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3949d43",
   "metadata": {},
   "source": [
    "## Race Data\n",
    "\n",
    "Obtain data from Race Day! \n",
    "\n",
    "Outcomes and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b07a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Race Data\n",
    "race_combined = pd.DataFrame(columns=[\"Driver\", \"Team\", \"GridPosition\", \"RacePosition\", \"Status\", \n",
    "                                      \"Points\", \"PositionDifference\", \"Year\", \"GP\", \"ChampionshipPoints\", \n",
    "                                      \"LastRacePosition\", \"TeamChampionshipPoints\", \"TeammateLastRacePosition\"])\n",
    "\n",
    "# Loop through each year\n",
    "for year, gps in gps_by_year.items():\n",
    "\n",
    "    # Initialize dictionaries to keep track of championship standings\n",
    "    driver_points = {}\n",
    "    team_points = {}\n",
    "    last_race_positions = {}\n",
    "\n",
    "    \n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the race session data\n",
    "            session = fastf1.get_session(year, gp, 'R')\n",
    "            session.load()\n",
    "\n",
    "            # Extract relevant race results\n",
    "            results = session.results[[\"Abbreviation\", \"TeamName\", \"GridPosition\", \"Position\", \"Status\", \"Points\"]]\n",
    "            results[\"PositionDifference\"] = results[\"GridPosition\"] - results[\"Position\"]\n",
    "\n",
    "            # Update driver and team points\n",
    "            for _, row in results.iterrows():\n",
    "                driver = row[\"Abbreviation\"]\n",
    "                team = row[\"TeamName\"]\n",
    "                points = row[\"Points\"]\n",
    "                \n",
    "                if driver not in driver_points:\n",
    "                    driver_points[driver] = 0\n",
    "                if team not in team_points:\n",
    "                    team_points[team] = 0\n",
    "\n",
    "                driver_points[driver] += points\n",
    "                team_points[team] += points\n",
    "\n",
    "                # Last race position for the driver\n",
    "                last_race_positions[driver] = row[\"Position\"]\n",
    "\n",
    "            # Prepare the data for saving\n",
    "            race_data = []\n",
    "            for _, row in results.iterrows():\n",
    "                driver = row[\"Abbreviation\"]\n",
    "                team = row[\"TeamName\"]\n",
    "                \n",
    "                # Get points and positions\n",
    "                championship_points = driver_points[driver]\n",
    "                last_race_position = last_race_positions.get(driver, np.nan)\n",
    "                team_championship_points = team_points.get(team, np.nan)\n",
    "                \n",
    "                # Find teammate's last race position\n",
    "                teammates = results[results[\"TeamName\"] == team][\"Abbreviation\"].tolist()\n",
    "                teammates.remove(driver)\n",
    "                teammate_last_race_position = last_race_positions.get(teammates[0], np.nan) if teammates else np.nan\n",
    "\n",
    "                race_data.append({\n",
    "                    \"Driver\": driver,\n",
    "                    \"Team\": team,\n",
    "                    \"GridPosition\": row[\"GridPosition\"],\n",
    "                    \"RacePosition\": row[\"Position\"],\n",
    "                    \"Status\": row[\"Status\"],\n",
    "                    \"Points\": row[\"Points\"],\n",
    "                    \"PositionDifference\": row[\"PositionDifference\"],\n",
    "                    \"Year\": year,\n",
    "                    \"GP\": gp,\n",
    "                    \"ChampionshipPoints\": championship_points,\n",
    "                    \"LastRacePosition\": last_race_position,\n",
    "                    \"TeamChampionshipPoints\": team_championship_points,\n",
    "                    \"TeammateLastRacePosition\": teammate_last_race_position\n",
    "                })\n",
    "\n",
    "            # Combine the data\n",
    "            race_combined = pd.concat([race_combined, pd.DataFrame(race_data)], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {gp} {year}: {e}\")\n",
    "\n",
    "\n",
    "race_combined.to_csv(\"PaperRaceData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bca812",
   "metadata": {},
   "source": [
    "## Free Practices Data\n",
    "\n",
    "Covariates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd74106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP1 data\n",
    "\n",
    "fp1_combined = pd.DataFrame(columns=[\"Driver\", \"Team\", \"LapTime\", \"GapToFastestFP1\", \"Position\", \"Year\", \"GP\", \"Session\"])\n",
    "\n",
    "\n",
    "for year, gps in gps_by_year.items():\n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the FP1 session data\n",
    "            session = fastf1.get_session(year, gp, 'FP1')\n",
    "            session.load()\n",
    "\n",
    "            # Get all laps in the session\n",
    "            laps = session.laps\n",
    "\n",
    "            # Convert LapTime to total seconds\n",
    "            laps['LapTime'] = laps['LapTime'].dt.total_seconds()\n",
    "\n",
    "            # Drop rows with NaN LapTimes (e.g., if a driver did not set a valid lap time)\n",
    "            laps = laps.dropna(subset=['LapTime'])\n",
    "\n",
    "            # Get the fastest lap per driver\n",
    "            fastest_laps = laps.groupby('Driver').apply(lambda x: x.nsmallest(1, 'LapTime')).reset_index(drop=True)\n",
    "\n",
    "            # Find the fastest lap time in the session\n",
    "            session_fastest_time = fastest_laps[\"LapTime\"].min()\n",
    "\n",
    "            # Calculate the gap to the session's fastest lap for each driver's fastest lap\n",
    "            fastest_laps[\"GapToFastestFP1\"] = fastest_laps[\"LapTime\"] - session_fastest_time\n",
    "\n",
    "            # Extract the necessary columns and rename them\n",
    "            laps_data = fastest_laps[[\"Driver\", \"Team\", \"LapTime\", \"GapToFastestFP1\"]]\n",
    "            laps_data[\"Position\"] = laps_data[\"LapTime\"].rank().astype(int)  # Rank laps by time\n",
    "            laps_data[\"Year\"] = year\n",
    "            laps_data[\"GP\"] = gp\n",
    "            laps_data[\"Session\"] = \"FP1\"\n",
    "\n",
    "            # Combine the data\n",
    "            fp1_combined = pd.concat([fp1_combined, laps_data], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {gp} {year}: {e}\")\n",
    "\n",
    "\n",
    "fp1_combined.to_csv(\"PaperFP1Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c573840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP2 data\n",
    "fp2_combined = pd.DataFrame(columns=[\"Driver\", \"Team\", \"LapTime\", \"GapToFastestFP2\", \"Position\", \"Year\", \"GP\", \"Session\"])\n",
    "\n",
    "\n",
    "for year, gps in gps_by_year.items():\n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the FP2 session data\n",
    "            session = fastf1.get_session(year, gp, 'FP2')\n",
    "            session.load()\n",
    "\n",
    "            # Get all laps in the session\n",
    "            laps = session.laps\n",
    "\n",
    "            # Convert LapTime to total seconds\n",
    "            laps['LapTime'] = laps['LapTime'].dt.total_seconds()\n",
    "\n",
    "            # Drop rows with NaN LapTimes (e.g., if a driver did not set a valid lap time)\n",
    "            laps = laps.dropna(subset=['LapTime'])\n",
    "\n",
    "            # Get the fastest lap per driver\n",
    "            fastest_laps = laps.groupby('Driver').apply(lambda x: x.nsmallest(1, 'LapTime')).reset_index(drop=True)\n",
    "\n",
    "            # Find the fastest lap time in the session\n",
    "            session_fastest_time = fastest_laps[\"LapTime\"].min()\n",
    "\n",
    "            # Calculate the gap to the session's fastest lap for each driver's fastest lap\n",
    "            fastest_laps[\"GapToFastestFP2\"] = fastest_laps[\"LapTime\"] - session_fastest_time\n",
    "\n",
    "            # Extract the necessary columns and rename them\n",
    "            laps_data = fastest_laps[[\"Driver\", \"Team\", \"LapTime\", \"GapToFastestFP2\"]]\n",
    "            laps_data[\"Position\"] = laps_data[\"LapTime\"].rank().astype(int)  # Rank laps by time\n",
    "            laps_data[\"Year\"] = year\n",
    "            laps_data[\"GP\"] = gp\n",
    "            laps_data[\"Session\"] = \"FP2\"\n",
    "\n",
    "            # Combine the data\n",
    "            fp2_combined = pd.concat([fp1_combined, laps_data], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {gp} {year}: {e}\")\n",
    "\n",
    "# Save the combined data for all years to a single CSV file\n",
    "fp2_combined.to_csv(\"PaperFP2Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP3 Data\n",
    "fp3_combined = pd.DataFrame(columns=[\"Driver\", \"Team\", \"LapTime\", \"GapToFastestFP3\", \"Position\", \"Year\", \"GP\", \"Session\"])\n",
    "\n",
    "\n",
    "for year, gps in gps_by_year.items():\n",
    "    \n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the FP3 session data\n",
    "            session = fastf1.get_session(year, gp, 'FP3')\n",
    "            session.load()\n",
    "\n",
    "            # Get all laps in the session\n",
    "            laps = session.laps\n",
    "\n",
    "            # Convert LapTime to total seconds\n",
    "            laps['LapTime'] = laps['LapTime'].dt.total_seconds()\n",
    "\n",
    "            # Drop rows with NaN LapTimes (e.g., if a driver did not set a valid lap time)\n",
    "            laps = laps.dropna(subset=['LapTime'])\n",
    "\n",
    "            # Get the fastest lap per driver\n",
    "            fastest_laps = laps.groupby('Driver').apply(lambda x: x.nsmallest(1, 'LapTime')).reset_index(drop=True)\n",
    "\n",
    "            # Find the fastest lap time in the session\n",
    "            session_fastest_time = fastest_laps[\"LapTime\"].min()\n",
    "\n",
    "            # Calculate the gap to the session's fastest lap for each driver's fastest lap\n",
    "            fastest_laps[\"GapToFastestFP3\"] = fastest_laps[\"LapTime\"] - session_fastest_time\n",
    "\n",
    "            # Extract the necessary columns and rename them\n",
    "            laps_data = fastest_laps[[\"Driver\", \"Team\", \"LapTime\", \"GapToFastestFP3\"]]\n",
    "            laps_data[\"Position\"] = laps_data[\"LapTime\"].rank().astype(int)  # Rank laps by time\n",
    "            laps_data[\"Year\"] = year\n",
    "            laps_data[\"GP\"] = gp\n",
    "            laps_data[\"Session\"] = \"FP3\"\n",
    "\n",
    "            # Combine the data\n",
    "            fp3_combined = pd.concat([fp1_combined, laps_data], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {gp} {year}: {e}\")\n",
    "\n",
    "\n",
    "fp3_combined.to_csv(\"PaperFP3Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62139221",
   "metadata": {},
   "source": [
    "## Pitstop Data \n",
    "\n",
    "Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c438bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pitstop data\n",
    "pit_stop_data = pd.DataFrame(columns=[\"Driver\", \"Team\", \"Year\", \"GP\", \"StartingTyre\", \n",
    "                                      \"NumberOfPitStops\", \"TyresUsed\"])\n",
    "\n",
    "# Loop through each year\n",
    "for year, gps in gps_by_year.items():\n",
    "    # Loop through each GP for the current year\n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the race session data\n",
    "            session = fastf1.get_session(year, gp, 'R')\n",
    "            session.load()\n",
    "\n",
    "            # Extract lap data\n",
    "            laps = session.laps\n",
    "\n",
    "            # Initialize variables for each driver\n",
    "            driver_starting_tire = {}\n",
    "            driver_pit_stops = {}\n",
    "            driver_tires_used = {}\n",
    "\n",
    "            # Convert PitInTime to seconds\n",
    "            laps['PitOutTime'] = laps['PitOutTime'].dt.total_seconds()\n",
    "\n",
    "            # Filter laps to identify pit stops\n",
    "            pit_stops = laps[laps['PitOutTime'] > 0]\n",
    "\n",
    "            # Ensure we are not counting the first lap out of the pits\n",
    "            valid_pit_stops = pit_stops[pit_stops['LapNumber'] > 1]\n",
    "\n",
    "            # Loop through each lap to determine tire changes and pit stops\n",
    "            for _, lap in laps.iterrows():\n",
    "                driver = lap['Driver']\n",
    "                compound = lap['Compound']\n",
    "                \n",
    "                if driver not in driver_starting_tire:\n",
    "                    driver_starting_tire[driver] = compound\n",
    "                \n",
    "                if driver not in driver_pit_stops:\n",
    "                    driver_pit_stops[driver] = 0\n",
    "                \n",
    "                if driver not in driver_tires_used:\n",
    "                    driver_tires_used[driver] = []\n",
    "\n",
    "                # Append the tire compound to the list for this driver\n",
    "                if not driver_tires_used[driver] or driver_tires_used[driver][-1] != compound:\n",
    "                    driver_tires_used[driver].append(compound)\n",
    "\n",
    "            # Count the number of pit stops\n",
    "            for _, pit in valid_pit_stops.iterrows():\n",
    "                driver = pit['Driver']\n",
    "                driver_pit_stops[driver] += 1\n",
    "\n",
    "            # Prepare the data for saving\n",
    "            race_data = []\n",
    "            for driver in driver_starting_tire.keys():\n",
    "                race_data.append({\n",
    "                    \"Driver\": driver,\n",
    "                    \"Team\": session.results.loc[session.results[\"Abbreviation\"] == driver, \"TeamName\"].values[0],\n",
    "                    \"Year\": year,\n",
    "                    \"GP\": gp,\n",
    "                    \"StartingTire\": driver_starting_tire[driver],\n",
    "                    \"NumberOfPitStops\": driver_pit_stops.get(driver, 0),\n",
    "                    \"TiresUsed\": ', '.join(driver_tires_used.get(driver, []))\n",
    "                })\n",
    "\n",
    "            # Combine the data\n",
    "            pit_stop_data = pd.concat([pit_stop_data, pd.DataFrame(race_data)], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {gp} {year}: {e}\")\n",
    "\n",
    "# Save the pit stop data to a CSV file for verification\n",
    "pit_stop_data.to_csv(\"PitStopData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256740d",
   "metadata": {},
   "source": [
    "## Strategy Data \n",
    "\n",
    "Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8657adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategy data\n",
    "all_strategy_data = []\n",
    "\n",
    "# Loop through each year and each GP\n",
    "for year, gps in gps_by_year.items():\n",
    "    for gp in gps:\n",
    "        try:\n",
    "            # Load the race session for each GP and year \n",
    "            race = fastf1.get_session(year, gp, 'R')\n",
    "            race.load()\n",
    "\n",
    "            # Get the laps data for the race\n",
    "            laps = race.laps\n",
    "            drivers = race.drivers\n",
    "            drivers = [race.get_driver(driver)[\"Abbreviation\"] for driver in drivers]\n",
    "\n",
    "            # Extracting strategy information for each driver\n",
    "            for driver in drivers:\n",
    "                # Get driver details\n",
    "                driver_info = race.get_driver(driver)\n",
    "                team = driver_info[\"TeamName\"]\n",
    "                \n",
    "                # Filter laps for the current driver\n",
    "                driver_laps = laps[laps[\"Driver\"] == driver]\n",
    "\n",
    "                # Create a strategy string capturing compounds for each outlap\n",
    "                strategy = []\n",
    "\n",
    "                # Initialize the strategy with the starting compound\n",
    "                starting_compound = driver_laps['Compound'].iloc[0]\n",
    "                \n",
    "                strategy.append(starting_compound)\n",
    "\n",
    "                # Flag to skip the first outlap\n",
    "                first_outlap_skipped = False\n",
    "                for i in range(len(driver_laps)):\n",
    "                    # Check if the current lap is an outlap based on PitOutTime\n",
    "                    if driver_laps['PitOutTime'].dt.total_seconds().iloc[i] > 0:\n",
    "                        # Skip the first outlap\n",
    "                        if not first_outlap_skipped:\n",
    "                            first_outlap_skipped = True\n",
    "                            continue\n",
    "                        \n",
    "                        # Capture the compound used on this outlap\n",
    "                        outlap_compound = driver_laps['Compound'].iloc[i]\n",
    "                        strategy.append(outlap_compound)\n",
    "\n",
    "                # Join the strategy components with a '-'\n",
    "                strategy_string = '-'.join(strategy)\n",
    "\n",
    "                # Append the strategy data for this driver, GP, year, and team\n",
    "                all_strategy_data.append({\n",
    "                    'Driver': driver,\n",
    "                    'Team': team,\n",
    "                    'GP': gp, \n",
    "                    'Year': year,  \n",
    "                    'Strategy': strategy_string\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {gp} {year}: {e}\")\n",
    "\n",
    "# Convert the list of strategy data into a DataFrame\n",
    "strategy_df = pd.DataFrame(all_strategy_data)\n",
    "\n",
    "#Team mapping\n",
    "team_mapping = {\n",
    "    'Toro Rosso': 'RB',\n",
    "    'AlphaTauri':'RB',\n",
    "    'Renault': 'Alpine',\n",
    "    'Alfa Romeo Racing': 'Kick Sauber',\n",
    "    'Alfa Romeo': 'Kick Sauber',\n",
    "    'Racing Point': 'Aston Martin'\n",
    "}\n",
    "\n",
    "# Replace team names in the 'Team' column using the mapping\n",
    "strategy_df['Team'] = strategy_df['Team'].replace(team_mapping)\n",
    "\n",
    "strategy_df.to_csv(\"Strategy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b84b88",
   "metadata": {},
   "source": [
    "# Merge and additional variables construction \n",
    "\n",
    "Merge all the intermediate datasets to obtain the final dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eacfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge al the datasets \n",
    "\n",
    "# Load all the DataFrames\n",
    "q1 = pd.read_csv('PaperQ1Data.csv')    \n",
    "q2 = pd.read_csv('PaperQ2Data.csv')   \n",
    "race = pd.read_csv('PaperRaceData.csv')  \n",
    "FP1 = pd.read_csv('PaperFP1Data.csv')   \n",
    "FP2 = pd.read_csv('PaperFP2Data.csv')   \n",
    "FP3 = pd.read_csv('PaperFP3Data.csv')   \n",
    "pitstop=pd.read_csv('PitStopData.csv') \n",
    "\n",
    "\n",
    "q1 = q1.rename(columns={\"GapToKnockout\": \"GapToKnockoutQ1\"})\n",
    "q1 = q1.rename(columns={\"LapTime\": \"LapTimeQ1\"})\n",
    "q1 = q1.rename(columns={\"Position\": \"PositionQ1\"})\n",
    "q1 = q1.drop('Session', axis=1)\n",
    "\n",
    "q2= q2.rename(columns={\"GapToKnockout\": \"GapToKnockoutQ2\"})\n",
    "q2=q2.rename(columns={\"LapTime\": \"LapTimeQ2\"})\n",
    "q2 = q2.rename(columns={\"Position\": \"PositionQ2\"})\n",
    "q2 = q2.drop('Session', axis=1)\n",
    "\n",
    "FP1=FP1.rename(columns={\"LapTime\": \"LapTimeFP1\"})\n",
    "FP1=FP1.rename(columns={\"Position\": \"PositionFP1\"})\n",
    "FP1 = FP1.drop('Session', axis=1)\n",
    "\n",
    "FP2=FP2.rename(columns={\"LapTime\": \"LapTimeFP2\"})\n",
    "FP2=FP2.rename(columns={\"Position\": \"PositionFP2\"})\n",
    "FP2 = FP2.drop('Session', axis=1)\n",
    "\n",
    "FP3=FP3.rename(columns={\"LapTime\": \"LapTimeFP3\"})\n",
    "FP3=FP3.rename(columns={\"Position\": \"PositionFP3\"})\n",
    "FP3 = FP3.drop('Session', axis=1)\n",
    "\n",
    "\n",
    "# Start by merging q1 and q2\n",
    "merged_df = pd.merge(q1, q2, on=['GP', 'Year', 'Driver','Team'], how='left')\n",
    "\n",
    "# Merge the result with race data\n",
    "merged_df = pd.merge(merged_df, race, on=['GP', 'Year', 'Driver','Team'], how='left')\n",
    "\n",
    "# Merge with FP1\n",
    "merged_df = pd.merge(merged_df, FP1, on=['GP', 'Year', 'Driver','Team'], how='left')\n",
    "\n",
    "# Merge with FP2\n",
    "merged_df = pd.merge(merged_df, FP2, on=['GP', 'Year', 'Driver','Team'], how='left')\n",
    "\n",
    "# Merge with FP3\n",
    "merged_df = pd.merge(merged_df, FP3, on=['GP', 'Year', 'Driver','Team'], how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, pitstop, on=['GP', 'Year', 'Driver','Team'], how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Treatment Variables, Dummies \n",
    "\n",
    "#Treatment \n",
    "# Create a new variable to indicate if the driver made it to Q2\n",
    "merged_df['MadeItToQ2'] = (merged_df['GapToKnockoutQ1'] <= 0).astype(int)\n",
    "\n",
    "# Create a new variable to indicate if the driver made it to Q3\n",
    "merged_df['MadeItToQ3'] = (merged_df['GapToKnockoutQ2'] <= 0).astype(int)\n",
    "\n",
    "#Starting Tyre Dummies\n",
    "dummies = merged_df.get_dummies(merged_df['StartingTyre'], prefix='Tyre', prefix_sep='').astype(int)\n",
    "merged_df = merged_df.concat([merged_df, dummies], axis=1)\n",
    "\n",
    "#Dummy for Pitlane Start\n",
    "merged_df['Pitlane'] = (merged_df['GridPosition'] == 0).astype(int)\n",
    "\n",
    "#DNF Type Dummies \n",
    "\n",
    "dnf_driving = [\n",
    "    'Collision damage', 'Collision', 'Spun off', 'Accident', 'Damage'\n",
    "]\n",
    "\n",
    "dnf_mechanical = [\n",
    "    'Engine', 'Power Unit', 'Transmission', 'Oil leak', 'Fuel leak', 'Fuel pump', \n",
    "    'Exhaust', 'Hydraulics', 'Electronics', 'Fuel pressure', 'Gearbox', 'Mechanical', \n",
    "    'Undertray', 'Technical', 'Brakes', 'Suspension', 'Wheel', 'Power loss', 'Puncture', \n",
    "    'Radiator', 'Wheel nut', 'Driveshaft', 'Electrical', 'Turbo', 'Rear wing', 'Vibrations', \n",
    "    'Water leak', 'Front wing', 'Cooling system', 'Water pump', 'Differential', 'Steering', \n",
    "    'Debris'\n",
    "]\n",
    "\n",
    "merged_df['DNFDriving'] = merged_df['Status'].isin(dnf_driving).astype(int)\n",
    "\n",
    "\n",
    "merged_df['DNFMechanical'] = merged_df['Status'].isin(dnf_mechanical).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final dataset to csv\n",
    "merged_df.to_csv(\"FinalDataSet.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
